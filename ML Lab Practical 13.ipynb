{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu3wKg6fzFHv"
      },
      "source": [
        "Lab 13: Implement a Basic Artificial Neural Network\n",
        "This script demonstrates implementation of a basic ANN using TensorFlow/Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "N7Jbj-34zFHx"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Try to import tensorflow/keras, provide fallback message if not available\n",
        "try:\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Dropout\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    KERAS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    KERAS_AVAILABLE = False\n",
        "    print(\"TensorFlow/Keras not available. Install with: pip install tensorflow\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6UHQtXwSzFHy"
      },
      "outputs": [],
      "source": [
        "def simple_neural_network():\n",
        "    \"\"\"Demonstrate a simple neural network for classification\"\"\"\n",
        "    if not KERAS_AVAILABLE:\n",
        "        print(\"\\nSkipping: TensorFlow/Keras required\")\n",
        "        return\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Simple Neural Network\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    print(f\"\\nDataset: Iris\")\n",
        "    print(f\"Input shape: {X.shape}\")\n",
        "    print(f\"Number of classes: {len(np.unique(y))}\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "    y_test_cat = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "    # Create neural network\n",
        "    model = Sequential([\n",
        "        Dense(8, activation='relu', input_shape=(4,)),\n",
        "        Dense(6, activation='relu'),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\nModel Architecture:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nTraining model...\")\n",
        "    history = model.fit(\n",
        "        X_train_scaled, y_train_cat,\n",
        "        epochs=100,\n",
        "        batch_size=16,\n",
        "        validation_split=0.2,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_proba = model.predict(X_test_scaled, verbose=0)\n",
        "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('lab13_training_history.png')\n",
        "    plt.close()\n",
        "    print(\"\\nTraining history saved as 'lab13_training_history.png'\")\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kU7ynL-izFHz"
      },
      "outputs": [],
      "source": [
        "def deep_neural_network():\n",
        "    \"\"\"Demonstrate a deeper neural network\"\"\"\n",
        "    if not KERAS_AVAILABLE:\n",
        "        print(\"\\nSkipping: TensorFlow/Keras required\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Deep Neural Network with Dropout\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load digits dataset\n",
        "    digits = load_digits()\n",
        "    X = digits.data\n",
        "    y = digits.target\n",
        "\n",
        "    print(f\"\\nDataset: Handwritten Digits\")\n",
        "    print(f\"Input shape: {X.shape}\")\n",
        "    print(f\"Number of classes: {len(np.unique(y))}\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Normalize features\n",
        "    X_train_norm = X_train / 16.0\n",
        "    X_test_norm = X_test / 16.0\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "    y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "    # Create deep neural network with dropout\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(64,)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\nModel Architecture:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nTraining model...\")\n",
        "    history = model.fit(\n",
        "        X_train_norm, y_train_cat,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_accuracy = model.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_proba = model.predict(X_test_norm, verbose=0)\n",
        "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix - Deep Neural Network')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('lab13_deep_nn_confusion.png')\n",
        "    plt.close()\n",
        "    print(\"\\nConfusion matrix saved as 'lab13_deep_nn_confusion.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BoHBtPhOzFHz"
      },
      "outputs": [],
      "source": [
        "def activation_functions_comparison():\n",
        "    \"\"\"Compare different activation functions\"\"\"\n",
        "    if not KERAS_AVAILABLE:\n",
        "        print(\"\\nSkipping: TensorFlow/Keras required\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Comparing Activation Functions\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    # Prepare data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "    y_test_cat = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "    # Test different activation functions\n",
        "    activations = ['relu', 'tanh', 'sigmoid']\n",
        "    results = {}\n",
        "\n",
        "    for activation in activations:\n",
        "        model = Sequential([\n",
        "            Dense(8, activation=activation, input_shape=(4,)),\n",
        "            Dense(6, activation=activation),\n",
        "            Dense(3, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train_scaled, y_train_cat,\n",
        "            epochs=100,\n",
        "            batch_size=16,\n",
        "            validation_split=0.2,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        _, accuracy = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
        "        results[activation] = accuracy\n",
        "\n",
        "\n",
        "    # Visualize comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(results.keys(), results.values(), color=['blue', 'green', 'orange'])\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.title('Comparison of Activation Functions')\n",
        "    plt.ylim([0.9, 1.0])\n",
        "    for i, (act, acc) in enumerate(results.items()):\n",
        "        plt.text(i, acc + 0.005, f'{acc:.4f}', ha='center')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('lab13_activation_comparison.png')\n",
        "    plt.close()\n",
        "    print(\"\\nActivation comparison saved as 'lab13_activation_comparison.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2xLaP9YVzFHz"
      },
      "outputs": [],
      "source": [
        "def visualize_weights():\n",
        "    \"\"\"Visualize neural network weights\"\"\"\n",
        "    if not KERAS_AVAILABLE:\n",
        "        print(\"\\nSkipping: TensorFlow/Keras required\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Visualizing Network Weights\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Create and train a simple model\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    y_cat = to_categorical(y, num_classes=3)\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(4, activation='relu', input_shape=(4,)),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_scaled, y_cat, epochs=50, verbose=0)\n",
        "\n",
        "    # Get weights\n",
        "    weights = model.get_weights()\n",
        "\n",
        "    print(f\"\\nLayer 1 weights shape: {weights[0].shape}\")\n",
        "    print(f\"Layer 1 bias shape: {weights[1].shape}\")\n",
        "    print(f\"Layer 2 weights shape: {weights[2].shape}\")\n",
        "    print(f\"Layer 2 bias shape: {weights[3].shape}\")\n",
        "\n",
        "    # Visualize first layer weights\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(weights[0], cmap='coolwarm', center=0,\n",
        "                xticklabels=[f'Neuron {i+1}' for i in range(4)],\n",
        "                yticklabels=iris.feature_names)\n",
        "    plt.title('First Layer Weights')\n",
        "    plt.xlabel('Hidden Layer Neurons')\n",
        "    plt.ylabel('Input Features')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('lab13_weights_visualization.png')\n",
        "    plt.close()\n",
        "    print(\"\\nWeights visualization saved as 'lab13_weights_visualization.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JABs-IcIzFHz"
      },
      "outputs": [],
      "source": [
        "def manual_neural_network():\n",
        "    \"\"\"Implement a simple neural network manually\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Manual Neural Network Implementation\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Activation functions\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "    def sigmoid_derivative(x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    # Generate simple XOR dataset\n",
        "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "    print(\"\\nTraining on XOR problem:\")\n",
        "    print(\"Input:\\n\", X)\n",
        "    print(\"Expected Output:\\n\", y)\n",
        "\n",
        "    # Initialize weights\n",
        "    np.random.seed(42)\n",
        "    input_neurons = 2\n",
        "    hidden_neurons = 4\n",
        "    output_neurons = 1\n",
        "\n",
        "    weights_input_hidden = np.random.uniform(-1, 1, (input_neurons, hidden_neurons))\n",
        "    weights_hidden_output = np.random.uniform(-1, 1, (hidden_neurons, output_neurons))\n",
        "\n",
        "    learning_rate = 0.5\n",
        "    epochs = 10000\n",
        "\n",
        "    # Training\n",
        "    errors = []\n",
        "    for epoch in range(epochs):\n",
        "        # Forward propagation\n",
        "        hidden_input = np.dot(X, weights_input_hidden)\n",
        "        hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "        final_input = np.dot(hidden_output, weights_hidden_output)\n",
        "        final_output = sigmoid(final_input)\n",
        "\n",
        "        # Calculate error\n",
        "        error = y - final_output\n",
        "        errors.append(np.mean(np.abs(error)))\n",
        "\n",
        "        # Backpropagation\n",
        "        d_output = error * sigmoid_derivative(final_output)\n",
        "        error_hidden = d_output.dot(weights_hidden_output.T)\n",
        "        d_hidden = error_hidden * sigmoid_derivative(hidden_output)\n",
        "\n",
        "        # Update weights\n",
        "        weights_hidden_output += hidden_output.T.dot(d_output) * learning_rate\n",
        "        weights_input_hidden += X.T.dot(d_hidden) * learning_rate\n",
        "\n",
        "    print(f\"\\nTraining complete after {epochs} epochs\")\n",
        "    print(f\"Final error: {errors[-1]:.6f}\")\n",
        "\n",
        "    print(\"\\nPredictions:\")\n",
        "    for i in range(len(X)):\n",
        "        hidden = sigmoid(np.dot(X[i], weights_input_hidden))\n",
        "        output = sigmoid(np.dot(hidden, weights_hidden_output))\n",
        "        print(f\"Input: {X[i]} → Output: {output[0]:.4f} (Expected: {y[i][0]})\")\n",
        "\n",
        "    # Plot error over epochs\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(errors)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Absolute Error')\n",
        "    plt.title('Training Error Over Time (Manual NN)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('lab13_manual_nn_training.png')\n",
        "    plt.close()\n",
        "    print(\"\\nManual NN training plot saved as 'lab13_manual_nn_training.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BqWo8IcmzFH0"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main function to demonstrate artificial neural networks\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Lab 13: Artificial Neural Network\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Simple neural network\n",
        "    simple_neural_network()\n",
        "\n",
        "    # Deep neural network\n",
        "    deep_neural_network()\n",
        "\n",
        "    # Activation functions comparison\n",
        "    activation_functions_comparison()\n",
        "\n",
        "    # Visualize weights\n",
        "    visualize_weights()\n",
        "\n",
        "    # Manual implementation\n",
        "    manual_neural_network()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Lab 13 Complete!\")\n",
        "    print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H6ytSeOFzFH0",
        "outputId": "fca4387e-eca4-45cd-fa8b-038424973e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Lab 13: Artificial Neural Network\n",
            "==================================================\n",
            "==================================================\n",
            "Simple Neural Network\n",
            "==================================================\n",
            "\n",
            "Dataset: Iris\n",
            "Input shape: (150, 4)\n",
            "Number of classes: 3\n",
            "\n",
            "Model Architecture:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m54\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115\u001b[0m (460.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115</span> (460.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m115\u001b[0m (460.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115</span> (460.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model...\n",
            "Test Loss: 0.2860\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.78      0.88         9\n",
            "   virginica       0.85      1.00      0.92        11\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.95      0.93      0.93        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n",
            "\n",
            "Training history saved as 'lab13_training_history.png'\n",
            "\n",
            "==================================================\n",
            "Deep Neural Network with Dropout\n",
            "==================================================\n",
            "\n",
            "Dataset: Handwritten Digits\n",
            "Input shape: (1797, 64)\n",
            "Number of classes: 10\n",
            "\n",
            "Model Architecture:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,986\u001b[0m (74.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,986</span> (74.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,986\u001b[0m (74.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,986</span> (74.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model...\n",
            "Test Loss: 0.1091\n",
            "\n",
            "Confusion matrix saved as 'lab13_deep_nn_confusion.png'\n",
            "\n",
            "==================================================\n",
            "Comparing Activation Functions\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Activation comparison saved as 'lab13_activation_comparison.png'\n",
            "\n",
            "==================================================\n",
            "Visualizing Network Weights\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Layer 1 weights shape: (4, 4)\n",
            "Layer 1 bias shape: (4,)\n",
            "Layer 2 weights shape: (4, 3)\n",
            "Layer 2 bias shape: (3,)\n",
            "\n",
            "Weights visualization saved as 'lab13_weights_visualization.png'\n",
            "\n",
            "==================================================\n",
            "Manual Neural Network Implementation\n",
            "==================================================\n",
            "\n",
            "Training on XOR problem:\n",
            "Input:\n",
            " [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "Expected Output:\n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "\n",
            "Training complete after 10000 epochs\n",
            "Final error: 0.022058\n",
            "\n",
            "Predictions:\n",
            "Input: [0 0] → Output: 0.0277 (Expected: 0)\n",
            "Input: [0 1] → Output: 0.9855 (Expected: 1)\n",
            "Input: [1 0] → Output: 0.9747 (Expected: 1)\n",
            "Input: [1 1] → Output: 0.0207 (Expected: 0)\n",
            "\n",
            "Manual NN training plot saved as 'lab13_manual_nn_training.png'\n",
            "\n",
            "==================================================\n",
            "Lab 13 Complete!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}